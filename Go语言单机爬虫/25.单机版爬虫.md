# 单机版爬虫
## 爬虫
爬虫简单的理解就是从各个网络之上获取结构化的数据，就是网页转换成数据

go语言的爬虫库/框架
- henrylee2cn/pholcus
- gocrawl
- colly
- hu17889/go_spider


爬虫一般是一个递归过程，每一种类型的页面应该配置一个不同的解析器，从一个种子页面开始爬取，然后把爬取到的信息进行处理，这个页面的其他url放入一个任务队列里面排队，并附加一个对应的解析器。


## 爬虫的法律风险
- robots协议
- 技术上没有约束力
- 法律上仅作为参考
- 结果导向
- 使用常识进行判断
- QPS（每秒发送请求的数量）

## 开始第一个简单的爬虫
### 简单的请求
Golang中的net包封装了大部分网络相关的功能，我们基本不需要借助其他库就能实现我们的爬虫需求。其中最为常用的是http和url，使用前可以根据我们的需要进行导入：

```
import (
    "net/http"
    "net/url"
)
```
http提供了一些非常方便的接口，可以实现最简单的请求，例如Get、Post、Head：

```
resp, err := http.Get("http://example.com/")
...
resp, err := http.Post("http://example.com/upload", "image/jpeg", &buf)
...
resp, err := http.PostForm("http://example.com/form",
    url.Values{"key": {"Value"}, "id": {"123"}})
```
可以看到，我们非常简单的就发起了请求并获得了响应，这里需要注意一点的是，获得的响应body需要我们手动关闭：

```
package main

import (
	"fmt"
	"io/ioutil"
	"net/http"
)

func tryGet()  {
	resp,err := http.Get("http://www.baidu.com/")
	if err != nil {
		// 处理异常
	}
	defer resp.Body.Close()  // 函数结束时关闭Body
	body, err := ioutil.ReadAll(resp.Body)  // 读取Body
	fmt.Printf("%s",body)
}

func main()  {

	tryGet()

}

```
上述例子是我们对于百度页面的一个简单的抓取：

输出：

```
<!DOCTYPE html><!--STATUS OK-->


    <html><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta content="always" name="referrer"><meta name="theme-color" content="#2932e1"><meta name="description" content="全球领先的中文搜索引擎、致力于让网民更便捷地获取信息，找到所求。百度超过千亿的中文网页数据库，可以瞬间找到相关的搜索结果。"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" /><link rel="search" type="application/opensearchdescription+xml" href="/content-search.xml" title="百度搜索" />
    ......
```

就是这样简单的，我们爬取到了百度这个页面的数据。这样的请求方式是非常方便的，但是当我们需要定制我们请求的其他参数时，就必须要使用其他组件了。

### Client
Client是http包内部发起请求的组件，使用它，我们才可以去控制请求的超时、重定向和其他的设置。以下是Client的定义：

```
type Client struct {
    Transport     RoundTripper
    CheckRedirect func(req *Request, via []*Request) error
    Jar           CookieJar
    Timeout       time.Duration // Go 1.3
}
```
生成Client对象：
```
client := &http.Client{}
```
Client也有一些简便的请求方法：

```
resp, err := client.Get("http://example.com")

```
但这种方法与直接使用http.Get没多大差别，我们需要使用另一个方法来定制请求的Header、请求体、证书验证等参数，这就是Request和Do。

### Request
Request定义的字段，可以看到非常的多：

```
type Request struct {
    Method           string
    URL              *url.URL
    Proto            string // "HTTP/1.0"
    ProtoMajor       int    // 1
    ProtoMinor       int    // 0
    Header           Header
    Body             io.ReadCloser
    GetBody          func() (io.ReadCloser, error)
    ContentLength    int64
    TransferEncoding []string
    Close            bool
    Host             string
    Form             url.Values
    PostForm         url.Values
    MultipartForm    *multipart.Form
    Trailer          Header
    RemoteAddr       string
    RequestURI       string
    TLS              *tls.ConnectionState
    Cancel           <-chan struct{}
    Response         *Response
}
```
使用http提供的NewRequest方法来生成Request，此方法中做了一些生成Request的默认设置，以下是NewRequest的函数签名：
```
func NewRequest(method, url string, body io.Reader) (*Request, error)
```
参数中method和url两个是必备参数，而body参数，在使用没有body的请求方法时，传入nil即可。

配置好Request之后，使用Client对象的Do方法，就可以将Request发送出去，以下是示例：

```
req, err := NewRequest("Get", "http://www.baidu.com", nil)
resp, err := client.Do(req)
```

#### Method
请求方法，必备的参数，如果为空字符则表示Get请求。
#### URL
一个被解析过的url结构体。
#### Proto

HTTP协议版本。

在Go中，HTTP请求会默认使用HTTP1.1，而HTTPS请求会默认首先使用HTTP2.0，如果目标服务器不支持，握手失败后才会改用HTTP1.1。

如果希望强制使用HTTP2.0的协议，那么需要使用 golang.org/x/net/http2 这个包所提供的功能。
#### 发起Post请求
如果要使用Request发起Post请求，提交表单的话，可以用到它的PostForm字段，这是一个类型为url.Values的字段，以下为示例：

```
req, err := NewRequest("Post", "https://www.baidu.com", nil)
req.PostForm.Add("key", "value")
```

#### 设置Header
Header的类型是http.Header，其中包含着之前请求中返回的header和client发送的header。

可以使用这种方式设置Header：

```
req, err := NewRequest("Get", "https://www.baidu.com", nil)
req.Header.Add("key", "value")
```

#### 添加Cookie
给特定的请求手动设置Cookie，这个时候就可以使用Request对象的AddCookie方法，这是其函数签名：

```
func (r *Request) AddCookie(c *Cookie)
```
其传入的参数是Cookie类型，，以下是此类型包含的属性：
```
type Cookie struct {
    Name       string
    Value      string
    Path       string
    Domain     string
    Expires    time.Time
    RawExpires string
    MaxAge     int
    Secure     bool
    HttpOnly   bool
    Raw        string
    Unparsed   []string
}
```
其中只有Name和Value是必须的，所以以下是添加Cookie的示例：

```
c := &http.Cookie{
    Name:  "key",
    Value: "value",
}
req.AddCookie(c)
```


## 爬取豆瓣TOP250榜单

### 对于页面进行分析
首先我们发现TOP250榜单进行了分页，每一页的链接大致为：https://movie.douban.com/top250?start=0&filter=

请求发生变化的只是start参数，所以我们对于每一页的爬取只需要修改start参数就可以


实例（对于一个页面的爬取）：

```
package main

import (
	"fmt"
	"io/ioutil"
	"net/http"
)

func getWebContent(url string) {
	client := &http.Client{}
	request, err := http.NewRequest("GET", url, nil)
	request.Header.Add("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9") // 增加请求报文头
	request.Header.Add("User-Agent","Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36")
	if err != nil {
		fmt.Println(err)
	}

	resp, err := client.Do(request)
	if err != nil {
		fmt.Println(err)
	}
	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Println(err)
	}
	fmt.Println(string(body))
}

func main()  {

	base_url := "https://movie.douban.com/top250?start=0&filter="
	getWebContent(base_url)

}

```

输出：

```
 <li>
            <div class="item">
                <div class="pic">
                    <em class="">1</em>
                    <a href="https://movie.douban.com/subject/1292052/">
                        <img width="100" alt="肖申克的救赎" src="https://img2.doubanio.com/view/photo/s_ratio_poster/public/p480747492.webp" class="">
                    </a>
                </div>
                <div class="info">
                    <div class="hd">
                        <a href="https://movie.douban.com/subject/1292052/" class="">
                            <span class="title">肖申克的救赎</span>
                                    <span class="title">&nbsp;/&nbsp;The Shawshank Redemption</span>
                                <span class="other">&nbsp;/&nbsp;月黑高飞(港)  /  刺激1995(台)</span>
                        </a>


                            <span class="playable">[可播放]</span>
                    </div>
                    <div class="bd">
                        <p class="">
                            导演: 弗兰克·德拉邦特 Frank Darabont&nbsp;&nbsp;&nbsp;主演: 蒂姆·罗宾斯 Tim Robbins /...<br>
                            1994&nbsp;/&nbsp;美国&nbsp;/&nbsp;犯罪 剧情
                        </p>

                        
                        <div class="star">
                                <span class="rating5-t"></span>
                                <span class="rating_num" property="v:average">9.7</span>
                                <span property="v:best" content="10.0"></span>
                                <span>2420311人评价</span>
                        </div>

                            <p class="quote">
                                <span class="inq">希望让人自由。</span>
                            </p>
                    </div>
                </div>
            </div>
        </li>
        <li>
            <div class="item">
                <div class="pic">
                    <em class="">2</em>
                    <a href="https://movie.douban.com/subject/1291546/">
                        <img width="100" alt="霸王别姬" src="https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2561716440.webp" class="">
                    </a>
        .....
```


### 使用正则表达式对于数据的提取
获取电影名：

正则表达式：

```
regexp.MustCompile("<span class=\"title\">([^&]+)</span>")
```

实例：

```
func getWebContent(url string) {
	client := &http.Client{}
	request, err := http.NewRequest("GET", url, nil)
	request.Header.Add("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9") // 增加请求报文头
	request.Header.Add("User-Agent","Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36")
	if err != nil {
		fmt.Println(err)
	}

	resp, err := client.Do(request)
	if err != nil {
		fmt.Println(err)
	}
	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Println(err)
	}

	getMovies(body)
}

func getMovies(body []byte) {

	 Name := regexp.MustCompile("<span class=\"title\">([^&]+)</span>")
	 matches := Name.FindAll(body,-1)
	for _,m := range matches{
		fmt.Printf("%s\n",m)
	}
	fmt.Println(len(matches))

}

func main()  {

	base_url := "https://movie.douban.com/top250?start=0&filter="
	getWebContent(base_url)

}

```

输出：

```
<span class="title">肖申克的救赎</span>
<span class="title">霸王别姬</span>
<span class="title">阿甘正传</span>
<span class="title">这个杀手不太冷</span>
<span class="title">泰坦尼克号</span>
<span class="title">美丽人生</span>
<span class="title">千与千寻</span>
<span class="title">辛德勒的名单</span>
<span class="title">盗梦空间</span>
<span class="title">忠犬八公的故事</span>
<span class="title">星际穿越</span>
<span class="title">楚门的世界</span>
<span class="title">海上钢琴师</span>
<span class="title">三傻大闹宝莱坞</span>
<span class="title">机器人总动员</span>
<span class="title">放牛班的春天</span>
<span class="title">无间道</span>
<span class="title">疯狂动物城</span>
<span class="title">大话西游之大圣娶亲</span>
<span class="title">熔炉</span>
<span class="title">教父</span>
<span class="title">当幸福来敲门</span>
<span class="title">龙猫</span>
<span class="title">怦然心动</span>
<span class="title">控方证人</span>
25
```


进行输出的修改：

```
package main

import (
	"fmt"
	"io/ioutil"
	"net/http"
	"regexp"
)

func tryGet()  {
	resp,err := http.Get("http://www.baidu.com/")
	if err != nil {
		// 处理异常
	}
	defer resp.Body.Close()  // 函数结束时关闭Body
	body, err := ioutil.ReadAll(resp.Body)  // 读取Body
	fmt.Printf("%s",body)
}

func getWebContent(url string) {
	client := &http.Client{}
	request, err := http.NewRequest("GET", url, nil)
	request.Header.Add("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9") // 增加请求报文头
	request.Header.Add("User-Agent","Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36")
	if err != nil {
		fmt.Println(err)
	}

	resp, err := client.Do(request)
	if err != nil {
		fmt.Println(err)
	}
	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Println(err)
	}

	getMovies(body)
}

func getMovies(body []byte) {

	 Name := regexp.MustCompile("<span class=\"title\">([^&]+)</span>")
	 matches := Name.FindAllSubmatch(body,-1)
	for _,m := range matches{
		fmt.Printf("%s\n",m[1])
	}
	fmt.Println(len(matches))

}

func main()  {

	base_url := "https://movie.douban.com/top250?start=%d&filter="
	for i := 0; i < 10; i++ {
		url := fmt.Sprintf(base_url, i*25)
		getWebContent(url)
	}


}

```

输出：

```
肖申克的救赎
霸王别姬
阿甘正传
这个杀手不太冷
泰坦尼克号
美丽人生
千与千寻
辛德勒的名单
盗梦空间
忠犬八公的故事
星际穿越
楚门的世界
海上钢琴师
三傻大闹宝莱坞
机器人总动员
.....
```














 